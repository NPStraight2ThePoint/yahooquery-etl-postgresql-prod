# ğŸ“Š Yahoo Finance ETL to PostgreSQL

**Automated, scalable, and modular ETL pipeline** using [`yahooquery`](https://github.com/dpguthrie/yahooquery) to extract pricing, financial statements, and fundamental data â€” all stored in a **PostgreSQL database** for easy querying and analysis.

---

## ğŸš€ Features

- âœ… Clean, plug-and-play ETL pipeline (3 segments: Pricing, Financials, Fundamentals)
- ğŸ“¥ Automatically scrapes S&P 500 tickers (or lets you configure your own universe)
- ğŸ§± Creates and manages PostgreSQL database schema + tables
- ğŸ—ƒï¸ Organized output directories, archiving logic and file handling
- âš™ï¸ Fully modular: update or extend segments easily
- ğŸ”’ Secure `.env` config (example provided)

---

## ğŸ“ Folder Structure

```text
yahooquery-etl-postgresql-prod/
â”œâ”€â”€ archive/                    # Archived CSVs for version tracking
â”‚   â””â”€â”€ data/
â”œâ”€â”€ archive_dir.py              # Archive logic
â”œâ”€â”€ etl/                        # ETL scripts for each data segment
â”‚   â”œâ”€â”€ _1_pricing/
â”‚   â”œâ”€â”€ _2_financial_statements/
â”‚   â””â”€â”€ _3_fundamentals/                   
â”œâ”€â”€ get_sp500_tickers.py        # Auto-download S&P 500 tickers
â”œâ”€â”€ global_orchestrator.py      # Runs all segments in order
â”œâ”€â”€ output/                     # Fetched raw data
â”‚   â”œâ”€â”€ _1_pricing/
â”‚   â”œâ”€â”€ _2_financials/
â”‚   â”œâ”€â”€ _3_fundamentals/
â”‚   â””â”€â”€ merged                  # Merged outputs
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_setup.py                # Runs DB creation, schema/tables & folder setup
â”œâ”€â”€ setup/                     
â”‚   â”œâ”€â”€ create_db.py
â”‚   â”œâ”€â”€ init_schema_tables.py
â”‚   â””â”€â”€ create_dirs.py
â”œâ”€â”€ sql_db_schema/              # CSV schema definition files
â”‚   â””â”€â”€ sql_schema.csv
â”œâ”€â”€ utils.py                    # Helper functions + shared paths
â”œâ”€â”€ .env.example                # Template for local credentials
â”œâ”€â”€ .gitignore                  # Excludes sensitive files
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Requirements

- Python 3.9+
- PostgreSQL (download [here](https://www.postgresql.org/download/))
- Libraries: see `requirements.txt`

### 2ï¸âƒ£ Clone the Repo

```bash
git clone https://github.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod.git
cd yahooquery-etl-postgresql-prod
```

### 3ï¸âƒ£ Set Up Environment

Create your .env file using the provided template:
```bash
cp .env.example .env
```
Edit .env with your local PostgreSQL credentials:
```bash
DB_HOST=localhost
DB_PORT=5432
DB_USER=your_username
DB_PASSWORD=your_password
DB_NAME=yahooquery_db
```
### 4ï¸âƒ£ Install Python Dependencies

We recommend using a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### ğŸ§± Initial Setup (One-time)

Run:
```bash
python _1_run_setup.py
```
### ğŸ› ï¸ Get Tickers
You have three flexible options for defining your ticker universe:

1. Run the script to auto-fetch the S&P 500: python _2_get_sp500_tickers.py
2. Manually replace the default ticker list in output/Static Data/Tickers.csv with your own list of tickers.
3. Edit the scraping logic inside _2_get_sp500_tickers.py
   to adapt it to other universes â€” such as ASX 200, ETFs, or your own custom watchlist.

### ğŸ“ˆ Run the ETL Pipeline

You can either:

1. Use the Global Orchestrator (recommended):
```bash
python _3_global_orchestrator.py
```

Or:

2. Run each module manually (pricing, financials, fundamentals):

```bash
python etl/_1_pricing/pricing_orchestrator.py
python etl/_2_financial_statements/financials_statements_orchestrator.py
python etl/_3_fundamentals/fundamentals_orchestrator.py
```

ğŸ“¦ Archive Old Data (Optional)
After a run, clean up and archive raw data:

```bash
python _4_archive_dir.py
```

ğŸ“Š What's Included
```bash
ğŸ“ Historical pricing
ğŸ“ Option chains
ğŸ“ Technical insights
ğŸ“ Financial statements (IS, BS, CF) / (Annual/Quarterly)
ğŸ“ Company fundamentals
ğŸ“ Static profiles, summaries, and more
```
## Visual Overview

### Setup
![Setup](https://raw.githubusercontent.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod/main/visuals/setup.png)

### ETL Process
![ETL](https://raw.githubusercontent.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod/main/visuals/ETL.png)

### Database Schema
![Database](https://raw.githubusercontent.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod/main/visuals/Database.png)

---

### ğŸ§ª Project Status & Roadmap

âœ… Tested on 200 Tickers.

ğŸ“Œ **Upcoming Enhancements**:
- Automated testing
- GitHub Actions for CI/CD
- Additional Yahoo data modules

---

### ğŸ†” Project Info

**Author:** *Nicholas Papadimitris*  
**Created On:** *09 July 2025, 06:00 AM UTC*  
**Project ID:** `YF_YQ_ETL_09_Jul2025`

- ğŸ™ **GitHub:** [@NPStraight2ThePoint](https://github.com/NPStraight2ThePoint)  
- ğŸ’¼ **LinkedIn:** [Nicholas Papadimitris](https://www.linkedin.com/in/nicholas-papadimitris/)  
- ğŸ“§ **Email:** nicholas.papadimitris@gmail.com  

---

### ğŸ“„ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute.

---

### ğŸ™ Attribution Requirement

If you distribute or share this repository or its contents publicly, you **must**:

- âœ… Provide appropriate credit to the original author.
- âœ… Include a link to the original repository:  
  [https://github.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod](https://github.com/NPStraight2ThePoint/yahooquery-etl-postgresql-prod)
- âœ… Clearly indicate if any changes were made.

You may do so in any reasonable manner, **but not** in any way that suggests the original author or this repository endorses you or your use.

---

### ğŸ“¢ Third-Party Attributions

This project uses and builds upon the following external sources, which should be credited as per their own licenses:

- [`yahooquery`](https://github.com/dpguthrie/yahooquery): Python library for Yahoo Finance API, used here for data extraction.
- Data sourced from **Wikipedia** for S&P 500 constituents and related metadata.

Please refer to their respective licenses and terms when redistributing or modifying those components.








